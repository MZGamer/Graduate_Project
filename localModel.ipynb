{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "dic = {}\n",
    "with open('D:/Work/Project/School_Homework/Graduate_Project/predict_Model/reviewLabel/dict.json') as json_file:\n",
    "    dic = json.load(json_file)\n",
    "\n",
    "reverseDic=dict([(value,key) for (key,value) in dic.items()])\n",
    "\n",
    "def decode(encText):\n",
    "  dectext = \"\"\n",
    "  for id in encText:\n",
    "    if id in reverseDic:\n",
    "      dectext += reverseDic[id]\n",
    "    else:\n",
    "      dectext += \"#\"\n",
    "  return dectext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"),layers.Dense(embed_dim),] )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :]\n",
    "        attention_output = self.attention(inputs, inputs, attention_mask=mask)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim, })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(input_dim=input_dim, output_dim=output_dim)\n",
    "        self.position_embeddings = layers.Embedding(input_dim=sequence_length, output_dim=output_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"input_dim\": self.input_dim,})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Input, Dropout, Embedding, Flatten,MaxPooling1D,Conv1D,SimpleRNN,LSTM,GRU,Multiply,GlobalMaxPooling1D\n",
    "from keras.layers import Bidirectional,Activation,BatchNormalization,GlobalAveragePooling1D,MultiHeadAttention\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import concatenate\n",
    "import numpy as np\n",
    "np.random.seed(0)  # 指定随机数种子\n",
    "#单词索引的最大个数6000，单句话最大长度60\n",
    "top_words=len(dic)\n",
    "max_words=1000    #序列长度\n",
    "embed_dim=32    #嵌入维度\n",
    "num_labels=4   #10分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(top_words=top_words,max_words=max_words,num_labels=num_labels,mode='LSTM',hidden_dim=[64]):\n",
    "    if mode=='RNN':\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(top_words, input_length=max_words, output_dim=embed_dim, mask_zero=True))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(SimpleRNN(hidden_dim[0]))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(num_labels, activation=\"softmax\"))\n",
    "    elif mode=='MLP':\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(top_words, input_length=max_words, output_dim=embed_dim, mask_zero=True))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(hidden_dim[0], activation=\"relu\"))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(num_labels, activation=\"softmax\"))\n",
    "    elif mode=='GRU':\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(top_words, input_length=max_words, output_dim=embed_dim))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(GRU(hidden_dim[0]))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(num_labels, activation=\"softmax\"))\n",
    "    elif mode=='CNN':        #一维卷积\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(top_words, input_length=max_words, output_dim=embed_dim, mask_zero=True))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv1D(filters=32, kernel_size=3, padding=\"same\",activation=\"relu\"))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(hidden_dim[0], activation=\"relu\"))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(num_labels, activation=\"softmax\"))\n",
    "    elif mode=='CNN+LSTM':\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(top_words, input_length=max_words, output_dim=embed_dim))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv1D(filters=32, kernel_size=3, padding=\"same\",activation=\"relu\"))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(LSTM(hidden_dim[0]))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(num_labels, activation=\"softmax\"))\n",
    "    elif mode=='BiLSTM':\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(top_words, input_length=max_words, output_dim=embed_dim))\n",
    "        model.add(Bidirectional(LSTM(64)))\n",
    "        model.add(Dense(hidden_dim[0], activation='relu'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(num_labels, activation='softmax'))\n",
    "    #下面的网络采用Funcional API实现\n",
    "    elif mode=='TextCNN':\n",
    "        inputs = Input(name='inputs',shape=[max_words,], dtype='float64')\n",
    "        ## 词嵌入使用预训练的词向量\n",
    "        layer = Embedding(top_words, input_length=max_words, output_dim=embed_dim)(inputs)\n",
    "        ## 词窗大小分别为3,4,5\n",
    "        cnn1 = Conv1D(32, 3, padding='same', strides = 1, activation='relu')(layer)\n",
    "        cnn1 = MaxPooling1D(pool_size=2)(cnn1)\n",
    "        cnn2 = Conv1D(32, 4, padding='same', strides = 1, activation='relu')(layer)\n",
    "        cnn2 = MaxPooling1D(pool_size=2)(cnn2)\n",
    "        cnn3 = Conv1D(32, 5, padding='same', strides = 1, activation='relu')(layer)\n",
    "        cnn3 = MaxPooling1D(pool_size=2)(cnn3)\n",
    "        # 合并三个模型的输出向量\n",
    "        cnn = concatenate([cnn1,cnn2,cnn3], axis=-1)\n",
    "        x = Flatten()(cnn)\n",
    "        x = Dense(hidden_dim[0], activation='relu')(x)\n",
    "        output = Dense(num_labels, activation='softmax')(x)\n",
    "        model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    elif mode=='Attention':\n",
    "        inputs = Input(name='inputs',shape=[max_words,], dtype='float64')\n",
    "        x = Embedding(top_words, input_length=max_words, output_dim=embed_dim, mask_zero=True)(inputs)\n",
    "        x = MultiHeadAttention(1, key_dim=embed_dim)(x, x,x)\n",
    "        x = GlobalAveragePooling1D()(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Dense(32, activation='relu')(x)\n",
    "        output = Dense(num_labels, activation='softmax')(x)\n",
    "        model = Model(inputs=[inputs], outputs=output)\n",
    "\n",
    "    elif mode=='MultiHeadAttention':\n",
    "        inputs = Input(name='inputs',shape=[max_words,], dtype='float64')\n",
    "        x = Embedding(top_words, input_length=max_words, output_dim=embed_dim, mask_zero=True)(inputs)\n",
    "        x = MultiHeadAttention(8, key_dim=embed_dim)(x, x,x)\n",
    "        x = GlobalAveragePooling1D()(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Dense(32, activation='relu')(x)\n",
    "        output = Dense(num_labels, activation='softmax')(x)\n",
    "        model = Model(inputs=[inputs], outputs=output)\n",
    "\n",
    "    elif mode=='Attention+BiLSTM':\n",
    "        inputs = Input(name='inputs',shape=[max_words,], dtype='float64')\n",
    "        x = Embedding(top_words, input_length=max_words, output_dim=embed_dim)(inputs)\n",
    "        x = MultiHeadAttention(2, key_dim=embed_dim)(x, x,x)\n",
    "        x = Bidirectional(LSTM(hidden_dim[0]))(x)\n",
    "        x = Dense(64, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        output = Dense(num_labels, activation='softmax')(x)\n",
    "        model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    elif mode=='BiGRU+Attention':\n",
    "        inputs = Input(name='inputs',shape=[max_words,], dtype='float64')\n",
    "        x = Embedding(top_words, input_length=max_words, output_dim=embed_dim)(inputs)\n",
    "        x = Bidirectional(GRU(32,return_sequences=True))(x)\n",
    "        x = MultiHeadAttention(2, key_dim=embed_dim)(x,x,x)\n",
    "        x = Bidirectional(GRU(32))(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        output = Dense(num_labels, activation='softmax')(x)\n",
    "        model = Model(inputs=[inputs], outputs=output)\n",
    "\n",
    "    elif mode=='Transformer':\n",
    "        inputs = Input(name='inputs',shape=[max_words,], dtype='float64')\n",
    "        x = Embedding(top_words, input_length=max_words, output_dim=embed_dim, mask_zero=True)(inputs)\n",
    "        x = TransformerEncoder(embed_dim, 32, 4)(x)\n",
    "        x = GlobalMaxPooling1D()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        outputs = Dense(num_labels, activation='softmax')(x)\n",
    "        model = Model(inputs, outputs)\n",
    "\n",
    "    elif mode=='PositionalEmbedding+Transformer':\n",
    "        inputs = Input(name='inputs',shape=[max_words,], dtype='float64')\n",
    "        x= PositionalEmbedding(sequence_length=max_words, input_dim=top_words, output_dim=embed_dim)(inputs)\n",
    "        x = TransformerEncoder(embed_dim, 32, 4)(x)\n",
    "        x = GlobalMaxPooling1D()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        outputs = Dense(num_labels, activation='softmax')(x)\n",
    "        model = Model(inputs, outputs)\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义损失和精度的图,和混淆矩阵指标等等\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_loss(history):\n",
    "    # 显示训练和验证损失图表\n",
    "    plt.subplots(1,2,figsize=(10,3))\n",
    "    plt.subplot(121)\n",
    "    loss = history.history[\"loss\"]\n",
    "    epochs = range(1, len(loss)+1)\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    plt.plot(epochs, loss, \"bo\", label=\"Training Loss\")\n",
    "    plt.plot(epochs, val_loss, \"r\", label=\"Validation Loss\")\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.subplot(122)\n",
    "    acc = history.history[\"accuracy\"]\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "    plt.plot(epochs, acc, \"b-\", label=\"Training Acc\")\n",
    "    plt.plot(epochs, val_acc, \"r--\", label=\"Validation Acc\")\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "def plot_confusion_matrix(model,X_test,Y_test_original):\n",
    "    #dic2 = {0:\"Not_Relative\", 1:\"Very_Negative\", 2:\"Negative\", 3:\"Nature\", 4:\"Positive\", 5:\"Very_Positive\"}\n",
    "    dic2 = {0:\"Not_Relative\", 1:\"Negative\", 2:\"Nature\", 3:\"Positive\"}\n",
    "    #预测概率\n",
    "    prob=model.predict(X_test)\n",
    "    #预测类别\n",
    "    pred=np.argmax(prob,axis=1)\n",
    "    #数据透视表，混淆矩阵\n",
    "    pred=pd.Series(pred).map(dic2)\n",
    "    Y_test_original=pd.Series(Y_test_original).map(dic2)\n",
    "    table = pd.crosstab(Y_test_original, pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "    #print(table)\n",
    "    sns.heatmap(table,cmap='Blues',fmt='.20g', annot=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    #计算混淆矩阵的各项指标\n",
    "    print(classification_report(Y_test_original, pred))\n",
    "    #科恩Kappa指标\n",
    "    print('科恩Kappa'+str(cohen_kappa_score(Y_test_original, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义训练函数\n",
    "def train_fuc(max_words=max_words,mode='BiLSTM+Attention',batch_size=32,epochs=10,hidden_dim=[32],show_loss=True,show_confusion_matrix=True):\n",
    "    #构建模型\n",
    "    model=build_model(max_words=max_words,mode=mode)\n",
    "    print(model.summary())\n",
    "    es = EarlyStopping(patience=5)\n",
    "    with tf.device('/GPU:0'):\n",
    "      history=model.fit(X_train, Y_train,batch_size=batch_size,epochs=epochs,validation_split=0.2, verbose=1,callbacks=[es])\n",
    "    print('——————————-----------------——訓練完成—————-----------------------------———————')\n",
    "    # 评估模型\n",
    "    loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "    print(\"val DATA ACC: = {:.4f}\".format(accuracy))\n",
    "\n",
    "    if show_loss:\n",
    "        plot_loss(history)\n",
    "\n",
    "    if show_confusion_matrix:\n",
    "        plot_confusion_matrix(model=model,X_test=X_test,Y_test_original=Y_test_original)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def shuffle(Question, Answer, split_size):\n",
    "  x_train = []\n",
    "  x_val = []\n",
    "  y_train = []\n",
    "  y_val = []\n",
    "\n",
    "  trainSize = []\n",
    "  valSize = []\n",
    "\n",
    "  trainCount = []\n",
    "  valCount = []\n",
    "  dataSize = pd.Series(Answer).value_counts()\n",
    "  print(dataSize)\n",
    "  for i in range(len(dataSize)):\n",
    "    trainSize.append(dataSize[i] * (1 - split_size))\n",
    "    valSize.append(dataSize[i] - trainSize[i])\n",
    "    trainCount.append(0)\n",
    "    valCount.append(0)\n",
    "\n",
    "  for i in range(len(Question)):\n",
    "    dice = random.random()\n",
    "    choose = 0\n",
    "    if(dice <= split_size):\n",
    "      choose = 1\n",
    "\n",
    "    if(choose == 0):\n",
    "      if(trainCount[Answer[i]] < trainSize[Answer[i]]):\n",
    "        trainCount[Answer[i]] += 1\n",
    "        x_train.append(Question[i])\n",
    "        y_train.append(Answer[i])\n",
    "      else:\n",
    "        valCount[Answer[i]] += 1\n",
    "        x_val.append(Question[i])\n",
    "        y_val.append(Answer[i])\n",
    "    elif(choose == 1):\n",
    "      if(valCount[Answer[i]] < valCount[Answer[i]]):\n",
    "        valCount[Answer[i]] += 1\n",
    "        x_val.append(Question[i])\n",
    "        y_val.append(Answer[i])\n",
    "      else:\n",
    "        trainCount[Answer[i]] += 1\n",
    "        x_train.append(Question[i])\n",
    "        y_train.append(Answer[i])\n",
    "  print(pd.Series(y_train).value_counts())\n",
    "  print(pd.Series(y_val).value_counts())\n",
    "  return x_train, x_val, y_train, y_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model Create函数\n",
    "def create_model(max_words=max_words,mode='BiLSTM+Attention',batch_size=32,epochs=10,hidden_dim=[32],show_loss=True,show_confusion_matrix=True):\n",
    "    #构建模型\n",
    "    model=build_model(max_words=max_words,mode=mode)\n",
    "    print(model.summary())\n",
    "    es = EarlyStopping(patience=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 1000)]            0         \n",
      "                                                                 \n",
      " positional_embedding (Posi  (None, 1000, 32)          132608    \n",
      " tionalEmbedding)                                                \n",
      "                                                                 \n",
      " transformer_encoder (Trans  (None, 1000, 32)          19040     \n",
      " formerEncoder)                                                  \n",
      "                                                                 \n",
      " global_max_pooling1d (Glob  (None, 32)                0         \n",
      " alMaxPooling1D)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 151780 (592.89 KB)\n",
      "Trainable params: 151780 (592.89 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_words=len(dic)\n",
    "max_words=1000\n",
    "batch_size=16\n",
    "epochs=20\n",
    "show_confusion_matrix=True\n",
    "show_loss=True\n",
    "mode='PositionalEmbedding+Transformer'\n",
    "model = create_model(mode=mode,batch_size=batch_size,epochs=epochs,show_confusion_matrix=show_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"D:/Work/Project/School_Homework/Graduate_Project/predict_Model/reviewLabel/binFoodQualityV1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 1000)]            0         \n",
      "                                                                 \n",
      " positional_embedding_6 (Po  (None, 1000, 32)          132608    \n",
      " sitionalEmbedding)                                              \n",
      "                                                                 \n",
      " transformer_encoder_6 (Tra  (None, 1000, 32)          19040     \n",
      " nsformerEncoder)                                                \n",
      "                                                                 \n",
      " global_max_pooling1d_6 (Gl  (None, 32)                0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 151780 (592.89 KB)\n",
      "Trainable params: 151780 (592.89 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4573\n",
      "4573\n",
      "4064\n",
      "0    4064\n",
      "3     215\n",
      "1     149\n",
      "2     145\n",
      "Name: count, dtype: int64\n",
      "0    3408\n",
      "3     178\n",
      "1     126\n",
      "2     120\n",
      "Name: count, dtype: int64\n",
      "0    656\n",
      "3     37\n",
      "2     25\n",
      "1     23\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import emoji\n",
    "import re\n",
    "import math\n",
    "from pylab import mpl\n",
    "\n",
    "TARGET = 'food_quality'\n",
    "\n",
    "maxlen = 1000\n",
    "vocab_size = len(dic)\n",
    "# 讀取CSV文件並轉換為DataFrame\n",
    "df = pd.read_csv('maybeNegativeOrNature_foodQuality.csv')\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "texts = df['Comment'].tolist()\n",
    "\n",
    "full_size_labels = []\n",
    "full_size_encText = []\n",
    "\n",
    "labels = []\n",
    "encText = []\n",
    "\n",
    "Label0Max = float(\"INF\")\n",
    "Label0Count = 0\n",
    "\n",
    "\n",
    "PositiveMax = float(\"INF\")\n",
    "PositiveCount = 0\n",
    "for t in range(len(texts)):\n",
    "  texts[t] = emoji.demojize(texts[t])\n",
    "  texts[t] = re.sub(':\\S+?:', ' ', texts[t])\n",
    "  encs = []\n",
    "\n",
    "\n",
    "  if len(texts[t]) > maxlen:\n",
    "    texts[t] = texts[:maxlen]\n",
    "  for i in range(maxlen):\n",
    "    if(i<len(texts[t]) and texts[t][i] in dic):\n",
    "      encs.append(dic[texts[t][i]])\n",
    "    else:\n",
    "      encs.append(0)\n",
    "\n",
    "  if (encs != None) :\n",
    "    full_size_encText.append(encs)\n",
    "    if(df.iloc[t][TARGET] == 1 or df.iloc[t][TARGET] == 2):\n",
    "      full_size_labels.append(1)\n",
    "    elif(df.iloc[t][TARGET] == 4 or df.iloc[t][TARGET] == 5):\n",
    "      full_size_labels.append(3)\n",
    "    elif(df.iloc[t][TARGET] == 3):\n",
    "      full_size_labels.append(2)\n",
    "    else:\n",
    "      full_size_labels.append(df.iloc[t][TARGET]) \n",
    "\n",
    "\n",
    "  if (df.iloc[t][TARGET] == 0):\n",
    "    if(Label0Count > Label0Max):\n",
    "      continue\n",
    "    Label0Count += 1\n",
    "\n",
    "  if(df.iloc[t][TARGET] == 1 or df.iloc[t][TARGET] == 2):\n",
    "    labels.append(1)\n",
    "  elif(df.iloc[t][TARGET] == 4 or df.iloc[t][TARGET] == 5):\n",
    "    if(PositiveCount > PositiveMax):\n",
    "      continue\n",
    "\n",
    "    PositiveCount += 1\n",
    "    labels.append(3)\n",
    "  elif(df.iloc[t][TARGET] == 3):\n",
    "    labels.append(2)\n",
    "  else:\n",
    "    labels.append(df.iloc[t][TARGET]) \n",
    "  #labels.append(df.iloc[t][TARGET])\n",
    "\n",
    "  '''if (df.iloc[t][TARGET] == 1):\n",
    "    labels.append(0)\n",
    "  elif (df.iloc[t][TARGET] == -1):\n",
    "    labels.append(1)\n",
    "  else:\n",
    "    labels.append(2)'''\n",
    "\n",
    "  encText.append(encs)\n",
    "\n",
    "\n",
    "\n",
    "print(len(labels))\n",
    "print(len(texts))\n",
    "print(pd.Series(labels).value_counts()[0])\n",
    "pd.Series(labels).value_counts().plot(kind='bar')\n",
    "# 將資料集分割成訓練集和測試集\n",
    "x_train, x_val, y_train, y_val = shuffle(encText, labels, 0.2)\n",
    "# 將標籤轉換為模型所需的格式\n",
    "label_dict = {label: i for i, label in enumerate(set(labels))}\n",
    "\n",
    "\n",
    "y_train = tf.constant([label_dict[label] for label in y_train], dtype=tf.int32)  # 將資料型別轉換為 tf.int32\n",
    "y_val = tf.constant([label_dict[label] for label in y_val], dtype=tf.int32)  # 將資料型別轉換為 tf.int32\n",
    "num_classes = len(label_dict)\n",
    "\n",
    "Y_train = tf.one_hot(y_train, num_classes)\n",
    "\n",
    "Y_test_original=y_val\n",
    "Y_test = tf.one_hot(y_val, num_classes)\n",
    "\n",
    "X_train = tf.constant(x_train)\n",
    "X_test = tf.constant(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # 指定使用的GPU索引\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233/233 [==============================] - 208s 892ms/step\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    ans = model.predict(full_size_encText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lebels 0's acc analyze:\n",
      "predict:[1141, 61, 52, 189, 0, 0]\n",
      "Total: 1443\n",
      "Acc: 0.7907137907137907 \n",
      "\n",
      "lebels 1's acc analyze:\n",
      "predict:[63, 394, 66, 74, 0, 0]\n",
      "Total: 597\n",
      "Acc: 0.6599664991624791 \n",
      "\n",
      "lebels 2's acc analyze:\n",
      "predict:[59, 30, 352, 107, 0, 0]\n",
      "Total: 548\n",
      "Acc: 0.6423357664233577 \n",
      "\n",
      "lebels 3's acc analyze:\n",
      "predict:[670, 210, 468, 3515, 0, 0]\n",
      "Total: 4863\n",
      "Acc: 0.7228048529714168 \n",
      "\n",
      "Total: \n",
      "[[1141, 61, 52, 189, 0, 0], [63, 394, 66, 74, 0, 0], [59, 30, 352, 107, 0, 0], [670, 210, 468, 3515, 0, 0]]\n",
      "0.7250033552543282\n",
      "Alert\n"
     ]
    }
   ],
   "source": [
    "chk = [[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0]]\n",
    "''',[0,0,0,0,0,0],[0,0,0,0,0,0]]'''\n",
    "correct = 0\n",
    "positive = [4,5]\n",
    "negative = [1,2]\n",
    "nature = [3]\n",
    "\n",
    "checkLabel = full_size_labels\n",
    "alert = []\n",
    "for i in range(len(checkLabel)):\n",
    "  chk[checkLabel[i]][np.argmax(ans[i])] += 1\n",
    "  if checkLabel[i] == np.argmax(ans[i]):\n",
    "    correct += 1\n",
    "  if(checkLabel[i] in negative and np.argmax(ans[i]) in positive):\n",
    "    alert.append(i)\n",
    "\n",
    "for label in range(len(chk)):\n",
    "  print(f\"lebels {label}'s acc analyze:\")\n",
    "  print(f\"predict:{chk[label]}\")\n",
    "  print(f\"Total: {sum(chk[label])}\")\n",
    "  print(f\"Acc: {chk[label][label] / sum(chk[label])} \\n\")\n",
    "\n",
    "print(\"Total: \")\n",
    "print(chk)\n",
    "print(correct / len(checkLabel))\n",
    "\n",
    "print(\"Alert\")\n",
    "for i in alert:\n",
    "  print(decode(encText[i]))\n",
    "  print(f\"Ans:{checkLabel[i]}, Pred:{np.argmax(ans[i])}\")\n",
    "  print(ans[i])\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(string):\n",
    "    string = emoji.demojize(string)\n",
    "    string = re.sub(':\\S+?:', ' ', string)\n",
    "    encs = []\n",
    "    if len(string) > maxlen:\n",
    "        string = string[:maxlen]\n",
    "\n",
    "    for i in range(maxlen):\n",
    "        if(i<len(string) and string[i] in dic):\n",
    "            encs.append(dic[string[i]])\n",
    "        else:\n",
    "            encs.append(0)\n",
    "    if (encs != None) :\n",
    "        return encs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "[[0.7655105  0.03964278 0.06860557 0.12624112]]\n",
      "Pred:0\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "import re\n",
    "maxlen = 1000\n",
    "testCase = \" 看了美食部落客花露露的文章慕名而來，點了一個松露牛肉漢堡跟老墨雞腿漢堡，好吃到爆！漢堡物超所值的大顆，而且店員服務態度很好， 絕對絕對會再回訪的好店（已放入口袋名單）\"\n",
    "encText = []\n",
    "encs = []\n",
    "encText.append(encode(testCase))\n",
    "print(len(encText))\n",
    "predictions = model.predict(encText)\n",
    "print(predictions)\n",
    "print(f\"Pred:{np.argmax(predictions[0])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

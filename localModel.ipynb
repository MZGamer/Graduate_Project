{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "dic = {}\n",
    "with open('D:/Work/Project/School_Homework/Graduate_Project/predict_Model/reviewLabel/dict.json') as json_file:\n",
    "    dic = json.load(json_file)\n",
    "\n",
    "reverseDic=dict([(value,key) for (key,value) in dic.items()])\n",
    "\n",
    "def decode(encText):\n",
    "  dectext = \"\"\n",
    "  for id in encText:\n",
    "    if id in reverseDic:\n",
    "      dectext += reverseDic[id]\n",
    "    else:\n",
    "      dectext += \"#\"\n",
    "  return dectext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"),layers.Dense(embed_dim),] )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :]\n",
    "        attention_output = self.attention(inputs, inputs, attention_mask=mask)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim, })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(input_dim=input_dim, output_dim=output_dim)\n",
    "        self.position_embeddings = layers.Embedding(input_dim=sequence_length, output_dim=output_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"input_dim\": self.input_dim,})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Input, Dropout, Embedding, Flatten,MaxPooling1D,Conv1D,SimpleRNN,LSTM,GRU,Multiply,GlobalMaxPooling1D\n",
    "from keras.layers import Bidirectional,Activation,BatchNormalization,GlobalAveragePooling1D,MultiHeadAttention\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import concatenate\n",
    "import numpy as np\n",
    "np.random.seed(0)  # 指定随机数种子\n",
    "#单词索引的最大个数6000，单句话最大长度60\n",
    "top_words=len(dic)\n",
    "max_words=1000    #序列长度\n",
    "embed_dim=32    #嵌入维度\n",
    "num_labels=4   #10分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(top_words=top_words,max_words=max_words,num_labels=num_labels,mode='LSTM',hidden_dim=[64]):\n",
    "    if mode=='RNN':\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(top_words, input_length=max_words, output_dim=embed_dim, mask_zero=True))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(SimpleRNN(hidden_dim[0]))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(num_labels, activation=\"softmax\"))\n",
    "    elif mode=='MLP':\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(top_words, input_length=max_words, output_dim=embed_dim, mask_zero=True))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(hidden_dim[0], activation=\"relu\"))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(num_labels, activation=\"softmax\"))\n",
    "    elif mode=='GRU':\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(top_words, input_length=max_words, output_dim=embed_dim))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(GRU(hidden_dim[0]))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(num_labels, activation=\"softmax\"))\n",
    "    elif mode=='CNN':        #一维卷积\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(top_words, input_length=max_words, output_dim=embed_dim, mask_zero=True))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv1D(filters=32, kernel_size=3, padding=\"same\",activation=\"relu\"))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(hidden_dim[0], activation=\"relu\"))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(num_labels, activation=\"softmax\"))\n",
    "    elif mode=='CNN+LSTM':\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(top_words, input_length=max_words, output_dim=embed_dim))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv1D(filters=32, kernel_size=3, padding=\"same\",activation=\"relu\"))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(LSTM(hidden_dim[0]))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(num_labels, activation=\"softmax\"))\n",
    "    elif mode=='BiLSTM':\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(top_words, input_length=max_words, output_dim=embed_dim))\n",
    "        model.add(Bidirectional(LSTM(64)))\n",
    "        model.add(Dense(hidden_dim[0], activation='relu'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(num_labels, activation='softmax'))\n",
    "    #下面的网络采用Funcional API实现\n",
    "    elif mode=='TextCNN':\n",
    "        inputs = Input(name='inputs',shape=[max_words,], dtype='float64')\n",
    "        ## 词嵌入使用预训练的词向量\n",
    "        layer = Embedding(top_words, input_length=max_words, output_dim=embed_dim)(inputs)\n",
    "        ## 词窗大小分别为3,4,5\n",
    "        cnn1 = Conv1D(32, 3, padding='same', strides = 1, activation='relu')(layer)\n",
    "        cnn1 = MaxPooling1D(pool_size=2)(cnn1)\n",
    "        cnn2 = Conv1D(32, 4, padding='same', strides = 1, activation='relu')(layer)\n",
    "        cnn2 = MaxPooling1D(pool_size=2)(cnn2)\n",
    "        cnn3 = Conv1D(32, 5, padding='same', strides = 1, activation='relu')(layer)\n",
    "        cnn3 = MaxPooling1D(pool_size=2)(cnn3)\n",
    "        # 合并三个模型的输出向量\n",
    "        cnn = concatenate([cnn1,cnn2,cnn3], axis=-1)\n",
    "        x = Flatten()(cnn)\n",
    "        x = Dense(hidden_dim[0], activation='relu')(x)\n",
    "        output = Dense(num_labels, activation='softmax')(x)\n",
    "        model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    elif mode=='Attention':\n",
    "        inputs = Input(name='inputs',shape=[max_words,], dtype='float64')\n",
    "        x = Embedding(top_words, input_length=max_words, output_dim=embed_dim, mask_zero=True)(inputs)\n",
    "        x = MultiHeadAttention(1, key_dim=embed_dim)(x, x,x)\n",
    "        x = GlobalAveragePooling1D()(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Dense(32, activation='relu')(x)\n",
    "        output = Dense(num_labels, activation='softmax')(x)\n",
    "        model = Model(inputs=[inputs], outputs=output)\n",
    "\n",
    "    elif mode=='MultiHeadAttention':\n",
    "        inputs = Input(name='inputs',shape=[max_words,], dtype='float64')\n",
    "        x = Embedding(top_words, input_length=max_words, output_dim=embed_dim, mask_zero=True)(inputs)\n",
    "        x = MultiHeadAttention(8, key_dim=embed_dim)(x, x,x)\n",
    "        x = GlobalAveragePooling1D()(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Dense(32, activation='relu')(x)\n",
    "        output = Dense(num_labels, activation='softmax')(x)\n",
    "        model = Model(inputs=[inputs], outputs=output)\n",
    "\n",
    "    elif mode=='Attention+BiLSTM':\n",
    "        inputs = Input(name='inputs',shape=[max_words,], dtype='float64')\n",
    "        x = Embedding(top_words, input_length=max_words, output_dim=embed_dim)(inputs)\n",
    "        x = MultiHeadAttention(2, key_dim=embed_dim)(x, x,x)\n",
    "        x = Bidirectional(LSTM(hidden_dim[0]))(x)\n",
    "        x = Dense(64, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        output = Dense(num_labels, activation='softmax')(x)\n",
    "        model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    elif mode=='BiGRU+Attention':\n",
    "        inputs = Input(name='inputs',shape=[max_words,], dtype='float64')\n",
    "        x = Embedding(top_words, input_length=max_words, output_dim=embed_dim)(inputs)\n",
    "        x = Bidirectional(GRU(32,return_sequences=True))(x)\n",
    "        x = MultiHeadAttention(2, key_dim=embed_dim)(x,x,x)\n",
    "        x = Bidirectional(GRU(32))(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        output = Dense(num_labels, activation='softmax')(x)\n",
    "        model = Model(inputs=[inputs], outputs=output)\n",
    "\n",
    "    elif mode=='Transformer':\n",
    "        inputs = Input(name='inputs',shape=[max_words,], dtype='float64')\n",
    "        x = Embedding(top_words, input_length=max_words, output_dim=embed_dim, mask_zero=True)(inputs)\n",
    "        x = TransformerEncoder(embed_dim, 32, 4)(x)\n",
    "        x = GlobalMaxPooling1D()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        outputs = Dense(num_labels, activation='softmax')(x)\n",
    "        model = Model(inputs, outputs)\n",
    "\n",
    "    elif mode=='PositionalEmbedding+Transformer':\n",
    "        inputs = Input(name='inputs',shape=[max_words,], dtype='float64')\n",
    "        x= PositionalEmbedding(sequence_length=max_words, input_dim=top_words, output_dim=embed_dim)(inputs)\n",
    "        x = TransformerEncoder(embed_dim, 32, 4)(x)\n",
    "        x = GlobalMaxPooling1D()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        outputs = Dense(num_labels, activation='softmax')(x)\n",
    "        model = Model(inputs, outputs)\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义损失和精度的图,和混淆矩阵指标等等\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_loss(history):\n",
    "    # 显示训练和验证损失图表\n",
    "    plt.subplots(1,2,figsize=(10,3))\n",
    "    plt.subplot(121)\n",
    "    loss = history.history[\"loss\"]\n",
    "    epochs = range(1, len(loss)+1)\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    plt.plot(epochs, loss, \"bo\", label=\"Training Loss\")\n",
    "    plt.plot(epochs, val_loss, \"r\", label=\"Validation Loss\")\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.subplot(122)\n",
    "    acc = history.history[\"accuracy\"]\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "    plt.plot(epochs, acc, \"b-\", label=\"Training Acc\")\n",
    "    plt.plot(epochs, val_acc, \"r--\", label=\"Validation Acc\")\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "def plot_confusion_matrix(model,X_test,Y_test_original):\n",
    "    #dic2 = {0:\"Not_Relative\", 1:\"Very_Negative\", 2:\"Negative\", 3:\"Nature\", 4:\"Positive\", 5:\"Very_Positive\"}\n",
    "    dic2 = {0:\"Not_Relative\", 1:\"Negative\", 2:\"Nature\", 3:\"Positive\"}\n",
    "    #预测概率\n",
    "    prob=model.predict(X_test)\n",
    "    #预测类别\n",
    "    pred=np.argmax(prob,axis=1)\n",
    "    #数据透视表，混淆矩阵\n",
    "    pred=pd.Series(pred).map(dic2)\n",
    "    Y_test_original=pd.Series(Y_test_original).map(dic2)\n",
    "    table = pd.crosstab(Y_test_original, pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "    #print(table)\n",
    "    sns.heatmap(table,cmap='Blues',fmt='.20g', annot=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    #计算混淆矩阵的各项指标\n",
    "    print(classification_report(Y_test_original, pred))\n",
    "    #科恩Kappa指标\n",
    "    print('科恩Kappa'+str(cohen_kappa_score(Y_test_original, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义训练函数\n",
    "def train_fuc(max_words=max_words,mode='BiLSTM+Attention',batch_size=32,epochs=10,hidden_dim=[32],show_loss=True,show_confusion_matrix=True):\n",
    "    #构建模型\n",
    "    model=build_model(max_words=max_words,mode=mode)\n",
    "    print(model.summary())\n",
    "    es = EarlyStopping(patience=5)\n",
    "    with tf.device('/GPU:0'):\n",
    "      history=model.fit(X_train, Y_train,batch_size=batch_size,epochs=epochs,validation_split=0.2, verbose=1,callbacks=[es])\n",
    "    print('——————————-----------------——訓練完成—————-----------------------------———————')\n",
    "    # 评估模型\n",
    "    loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "    print(\"val DATA ACC: = {:.4f}\".format(accuracy))\n",
    "\n",
    "    if show_loss:\n",
    "        plot_loss(history)\n",
    "\n",
    "    if show_confusion_matrix:\n",
    "        plot_confusion_matrix(model=model,X_test=X_test,Y_test_original=Y_test_original)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def shuffle(Question, Answer, split_size):\n",
    "  x_train = []\n",
    "  x_val = []\n",
    "  y_train = []\n",
    "  y_val = []\n",
    "\n",
    "  trainSize = []\n",
    "  valSize = []\n",
    "\n",
    "  trainCount = []\n",
    "  valCount = []\n",
    "  dataSize = pd.Series(Answer).value_counts()\n",
    "  print(dataSize)\n",
    "  for i in range(len(dataSize)):\n",
    "    trainSize.append(dataSize[i] * (1 - split_size))\n",
    "    valSize.append(dataSize[i] - trainSize[i])\n",
    "    trainCount.append(0)\n",
    "    valCount.append(0)\n",
    "\n",
    "  for i in range(len(Question)):\n",
    "    dice = random.random()\n",
    "    choose = 0\n",
    "    if(dice <= split_size):\n",
    "      choose = 1\n",
    "\n",
    "    if(choose == 0):\n",
    "      if(trainCount[Answer[i]] < trainSize[Answer[i]]):\n",
    "        trainCount[Answer[i]] += 1\n",
    "        x_train.append(Question[i])\n",
    "        y_train.append(Answer[i])\n",
    "      else:\n",
    "        valCount[Answer[i]] += 1\n",
    "        x_val.append(Question[i])\n",
    "        y_val.append(Answer[i])\n",
    "    elif(choose == 1):\n",
    "      if(valCount[Answer[i]] < valCount[Answer[i]]):\n",
    "        valCount[Answer[i]] += 1\n",
    "        x_val.append(Question[i])\n",
    "        y_val.append(Answer[i])\n",
    "      else:\n",
    "        trainCount[Answer[i]] += 1\n",
    "        x_train.append(Question[i])\n",
    "        y_train.append(Answer[i])\n",
    "  print(pd.Series(y_train).value_counts())\n",
    "  print(pd.Series(y_val).value_counts())\n",
    "  return x_train, x_val, y_train, y_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model Create函数\n",
    "def create_model(max_words=max_words,mode='BiLSTM+Attention',batch_size=32,epochs=10,hidden_dim=[32],show_loss=True,show_confusion_matrix=True):\n",
    "    #构建模型\n",
    "    model=build_model(max_words=max_words,mode=mode)\n",
    "    print(model.summary())\n",
    "    es = EarlyStopping(patience=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 1000)]            0         \n",
      "                                                                 \n",
      " positional_embedding (Posi  (None, 1000, 32)          132608    \n",
      " tionalEmbedding)                                                \n",
      "                                                                 \n",
      " transformer_encoder (Trans  (None, 1000, 32)          19040     \n",
      " formerEncoder)                                                  \n",
      "                                                                 \n",
      " global_max_pooling1d (Glob  (None, 32)                0         \n",
      " alMaxPooling1D)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 151780 (592.89 KB)\n",
      "Trainable params: 151780 (592.89 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_words=len(dic)\n",
    "max_words=1000\n",
    "batch_size=16\n",
    "epochs=20\n",
    "show_confusion_matrix=True\n",
    "show_loss=True\n",
    "mode='PositionalEmbedding+Transformer'\n",
    "model = create_model(mode=mode,batch_size=batch_size,epochs=epochs,show_confusion_matrix=show_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"D:/Work/Project/School_Homework/Graduate_Project/predict_Model/reviewLabel/binFoodQualityV1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 1000)]            0         \n",
      "                                                                 \n",
      " positional_embedding_6 (Po  (None, 1000, 32)          132608    \n",
      " sitionalEmbedding)                                              \n",
      "                                                                 \n",
      " transformer_encoder_6 (Tra  (None, 1000, 32)          19040     \n",
      " nsformerEncoder)                                                \n",
      "                                                                 \n",
      " global_max_pooling1d_6 (Gl  (None, 32)                0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 151780 (592.89 KB)\n",
      "Trainable params: 151780 (592.89 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860\n",
      "4573\n",
      "701\n",
      "0    701\n",
      "1     65\n",
      "3     59\n",
      "2     35\n",
      "Name: count, dtype: int64\n",
      "0    583\n",
      "1     54\n",
      "3     50\n",
      "2     30\n",
      "Name: count, dtype: int64\n",
      "0    118\n",
      "1     11\n",
      "3      9\n",
      "2      5\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import emoji\n",
    "import re\n",
    "import math\n",
    "from pylab import mpl\n",
    "\n",
    "TARGET = 'food_quality'\n",
    "\n",
    "maxlen = 1000\n",
    "vocab_size = len(dic)\n",
    "# 讀取CSV文件並轉換為DataFrame\n",
    "df = pd.read_csv('reviewTypeClean.csv')\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "texts = df['Comment'].tolist()\n",
    "\n",
    "full_size_labels = []\n",
    "full_size_encText = []\n",
    "\n",
    "labels = []\n",
    "encText = []\n",
    "\n",
    "Label0Max = 700\n",
    "Label0Count = 0\n",
    "\n",
    "\n",
    "PositiveMax = 700\n",
    "PositiveCount = 0\n",
    "for t in range(len(texts)):\n",
    "  texts[t] = emoji.demojize(texts[t])\n",
    "  texts[t] = re.sub(':\\S+?:', ' ', texts[t])\n",
    "  encs = []\n",
    "\n",
    "\n",
    "  if len(texts[t]) > maxlen:\n",
    "    texts[t] = texts[:maxlen]\n",
    "  for i in range(maxlen):\n",
    "    if(i<len(texts[t]) and texts[t][i] in dic):\n",
    "      encs.append(dic[texts[t][i]])\n",
    "    else:\n",
    "      encs.append(0)\n",
    "\n",
    "  if (encs != None) :\n",
    "    full_size_encText.append(encs)\n",
    "    if(df.iloc[t][TARGET] == 1 or df.iloc[t][TARGET] == 2):\n",
    "      full_size_labels.append(1)\n",
    "    elif(df.iloc[t][TARGET] == 4 or df.iloc[t][TARGET] == 5):\n",
    "      full_size_labels.append(3)\n",
    "    elif(df.iloc[t][TARGET] == 3):\n",
    "      full_size_labels.append(2)\n",
    "    else:\n",
    "      full_size_labels.append(df.iloc[t][TARGET]) \n",
    "\n",
    "\n",
    "  if (df.iloc[t][TARGET] == 0):\n",
    "    if(Label0Count > Label0Max):\n",
    "      continue\n",
    "    Label0Count += 1\n",
    "\n",
    "  if(df.iloc[t][TARGET] == 1 or df.iloc[t][TARGET] == 2):\n",
    "    labels.append(1)\n",
    "  elif(df.iloc[t][TARGET] == 4 or df.iloc[t][TARGET] == 5):\n",
    "    if(PositiveCount > PositiveMax):\n",
    "      continue\n",
    "\n",
    "    PositiveCount += 1\n",
    "    labels.append(3)\n",
    "  elif(df.iloc[t][TARGET] == 3):\n",
    "    labels.append(2)\n",
    "  else:\n",
    "    labels.append(df.iloc[t][TARGET]) \n",
    "  #labels.append(df.iloc[t][TARGET])\n",
    "\n",
    "  '''if (df.iloc[t][TARGET] == 1):\n",
    "    labels.append(0)\n",
    "  elif (df.iloc[t][TARGET] == -1):\n",
    "    labels.append(1)\n",
    "  else:\n",
    "    labels.append(2)'''\n",
    "\n",
    "  encText.append(encs)\n",
    "\n",
    "\n",
    "\n",
    "print(len(labels))\n",
    "print(len(texts))\n",
    "print(pd.Series(labels).value_counts()[0])\n",
    "pd.Series(labels).value_counts().plot(kind='bar')\n",
    "# 將資料集分割成訓練集和測試集\n",
    "x_train, x_val, y_train, y_val = shuffle(encText, labels, 0.2)\n",
    "# 將標籤轉換為模型所需的格式\n",
    "label_dict = {label: i for i, label in enumerate(set(labels))}\n",
    "\n",
    "\n",
    "y_train = tf.constant([label_dict[label] for label in y_train], dtype=tf.int32)  # 將資料型別轉換為 tf.int32\n",
    "y_val = tf.constant([label_dict[label] for label in y_val], dtype=tf.int32)  # 將資料型別轉換為 tf.int32\n",
    "num_classes = len(label_dict)\n",
    "\n",
    "Y_train = tf.one_hot(y_train, num_classes)\n",
    "\n",
    "Y_test_original=y_val\n",
    "Y_test = tf.one_hot(y_val, num_classes)\n",
    "\n",
    "X_train = tf.constant(x_train)\n",
    "X_test = tf.constant(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # 指定使用的GPU索引\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233/233 [==============================] - 208s 892ms/step\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    ans = model.predict(full_size_encText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lebels 0's acc analyze:\n",
      "predict:[1141, 61, 52, 189, 0, 0]\n",
      "Total: 1443\n",
      "Acc: 0.7907137907137907 \n",
      "\n",
      "lebels 1's acc analyze:\n",
      "predict:[63, 394, 66, 74, 0, 0]\n",
      "Total: 597\n",
      "Acc: 0.6599664991624791 \n",
      "\n",
      "lebels 2's acc analyze:\n",
      "predict:[59, 30, 352, 107, 0, 0]\n",
      "Total: 548\n",
      "Acc: 0.6423357664233577 \n",
      "\n",
      "lebels 3's acc analyze:\n",
      "predict:[670, 210, 468, 3515, 0, 0]\n",
      "Total: 4863\n",
      "Acc: 0.7228048529714168 \n",
      "\n",
      "Total: \n",
      "[[1141, 61, 52, 189, 0, 0], [63, 394, 66, 74, 0, 0], [59, 30, 352, 107, 0, 0], [670, 210, 468, 3515, 0, 0]]\n",
      "0.7250033552543282\n",
      "Alert\n"
     ]
    }
   ],
   "source": [
    "chk = [[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0]]\n",
    "''',[0,0,0,0,0,0],[0,0,0,0,0,0]]'''\n",
    "correct = 0\n",
    "positive = [4,5]\n",
    "negative = [1,2]\n",
    "nature = [3]\n",
    "\n",
    "checkLabel = full_size_labels\n",
    "alert = []\n",
    "for i in range(len(checkLabel)):\n",
    "  chk[checkLabel[i]][np.argmax(ans[i])] += 1\n",
    "  if checkLabel[i] == np.argmax(ans[i]):\n",
    "    correct += 1\n",
    "  if(checkLabel[i] in negative and np.argmax(ans[i]) in positive):\n",
    "    alert.append(i)\n",
    "\n",
    "for label in range(len(chk)):\n",
    "  print(f\"lebels {label}'s acc analyze:\")\n",
    "  print(f\"predict:{chk[label]}\")\n",
    "  print(f\"Total: {sum(chk[label])}\")\n",
    "  print(f\"Acc: {chk[label][label] / sum(chk[label])} \\n\")\n",
    "\n",
    "print(\"Total: \")\n",
    "print(chk)\n",
    "print(correct / len(checkLabel))\n",
    "\n",
    "print(\"Alert\")\n",
    "for i in alert:\n",
    "  print(decode(encText[i]))\n",
    "  print(f\"Ans:{checkLabel[i]}, Pred:{np.argmax(ans[i])}\")\n",
    "  print(ans[i])\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(string):\n",
    "    string = emoji.demojize(string)\n",
    "    string = re.sub(':\\S+?:', ' ', string)\n",
    "    encs = []\n",
    "    if len(string) > maxlen:\n",
    "        string = string[:maxlen]\n",
    "\n",
    "    for i in range(maxlen):\n",
    "        if(i<len(string) and string[i] in dic):\n",
    "            encs.append(dic[string[i]])\n",
    "        else:\n",
    "            encs.append(0)\n",
    "    if (encs != None) :\n",
    "        return encs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "[[0.0011213  0.011261   0.31213298 0.6754848 ]]\n",
      "Pred:3\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "import re\n",
    "maxlen = 1000\n",
    "testCase = \"吃過多家雞肉飯，覺得這家有合口味，雞肉絲多汁不材，滷汁也調味的很不錯，另外油豆腐個人也覺得入味好吃。\\n其他小菜⋯「筍絲」中規中矩、「紅糟肉」偏油偏肥，個人沒有很喜歡。\\n另外，用菜環境寬敞、乾淨；也有提供免費停車場。\"\n",
    "encText = []\n",
    "encs = []\n",
    "encText.append(encode(testCase))\n",
    "print(len(encText))\n",
    "predictions = model.predict(encText)\n",
    "print(predictions)\n",
    "print(f\"Pred:{np.argmax(predictions[0])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "dic = {}\n",
    "with open('D:/Work/Project/School_Homework/Graduate_Project/predict_Model/reviewLabel/dict.json') as json_file:\n",
    "    dic = json.load(json_file)\n",
    "\n",
    "reverseDic=dict([(value,key) for (key,value) in dic.items()])\n",
    "\n",
    "def decode(encText):\n",
    "  dectext = \"\"\n",
    "  for id in encText:\n",
    "    if id in reverseDic:\n",
    "      dectext += reverseDic[id]\n",
    "    else:\n",
    "      dectext += \"#\"\n",
    "  return dectext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"),layers.Dense(embed_dim),] )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :]\n",
    "        attention_output = self.attention(inputs, inputs, attention_mask=mask)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim, })\n",
    "        return config\n",
    "    \n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(input_dim=input_dim, output_dim=output_dim)\n",
    "        self.position_embeddings = layers.Embedding(input_dim=sequence_length, output_dim=output_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"input_dim\": self.input_dim,})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Input, Dropout, Embedding, Flatten,MaxPooling1D,Conv1D,SimpleRNN,LSTM,GRU,Multiply,GlobalMaxPooling1D\n",
    "from keras.layers import Bidirectional,Activation,BatchNormalization,GlobalAveragePooling1D,MultiHeadAttention\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import concatenate\n",
    "import numpy as np\n",
    "np.random.seed(0)  # 指定随机数种子\n",
    "#单词索引的最大个数6000，单句话最大长度60\n",
    "top_words=len(dic)\n",
    "max_words=1000    #序列长度\n",
    "embed_dim=32    #嵌入维度\n",
    "num_labels=4   #10分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(top_words=top_words,max_words=max_words,num_labels=num_labels,mode='LSTM',hidden_dim=[64]):\n",
    "    inputs = Input(name='inputs',shape=[max_words,], dtype='float64')\n",
    "    x= PositionalEmbedding(sequence_length=max_words, input_dim=top_words, output_dim=embed_dim)(inputs)\n",
    "    x = TransformerEncoder(embed_dim, 32, 4)(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_labels, activation='softmax')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义损失和精度的图,和混淆矩阵指标等等\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_loss(history):\n",
    "    # 显示训练和验证损失图表\n",
    "    plt.subplots(1,2,figsize=(10,3))\n",
    "    plt.subplot(121)\n",
    "    loss = history.history[\"loss\"]\n",
    "    epochs = range(1, len(loss)+1)\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    plt.plot(epochs, loss, \"bo\", label=\"Training Loss\")\n",
    "    plt.plot(epochs, val_loss, \"r\", label=\"Validation Loss\")\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.subplot(122)\n",
    "    acc = history.history[\"accuracy\"]\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "    plt.plot(epochs, acc, \"b-\", label=\"Training Acc\")\n",
    "    plt.plot(epochs, val_acc, \"r--\", label=\"Validation Acc\")\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "def plot_confusion_matrix(model,X_test,Y_test_original):\n",
    "    #dic2 = {0:\"Not_Relative\", 1:\"Very_Negative\", 2:\"Negative\", 3:\"Nature\", 4:\"Positive\", 5:\"Very_Positive\"}\n",
    "    dic2 = {0:\"Not_Relative\", 1:\"Negative\", 2:\"Nature\", 3:\"Positive\"}\n",
    "    #预测概率\n",
    "    prob=model.predict(X_test)\n",
    "    #预测类别\n",
    "    pred=np.argmax(prob,axis=1)\n",
    "    #数据透视表，混淆矩阵\n",
    "    pred=pd.Series(pred).map(dic2)\n",
    "    Y_test_original=pd.Series(Y_test_original).map(dic2)\n",
    "    table = pd.crosstab(Y_test_original, pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "    #print(table)\n",
    "    sns.heatmap(table,cmap='Blues',fmt='.20g', annot=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    #计算混淆矩阵的各项指标\n",
    "    print(classification_report(Y_test_original, pred))\n",
    "    #科恩Kappa指标\n",
    "    print('科恩Kappa'+str(cohen_kappa_score(Y_test_original, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义训练函数\n",
    "def train_fuc(max_words=max_words,mode='BiLSTM+Attention',batch_size=32,epochs=10,hidden_dim=[32],show_loss=True,show_confusion_matrix=True):\n",
    "    #构建模型\n",
    "    model=build_model(max_words=max_words,mode=mode)\n",
    "    print(model.summary())\n",
    "    es = EarlyStopping(patience=5)\n",
    "    with tf.device('/GPU:0'):\n",
    "      history=model.fit(X_train, Y_train,batch_size=batch_size,epochs=epochs,validation_split=0.2, verbose=1,callbacks=[es])\n",
    "    print('——————————-----------------——訓練完成—————-----------------------------———————')\n",
    "    # 评估模型\n",
    "    loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "    print(\"val DATA ACC: = {:.4f}\".format(accuracy))\n",
    "\n",
    "    if show_loss:\n",
    "        plot_loss(history)\n",
    "\n",
    "    if show_confusion_matrix:\n",
    "        plot_confusion_matrix(model=model,X_test=X_test,Y_test_original=Y_test_original)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def shuffle(Question, Answer, split_size):\n",
    "  x_train = []\n",
    "  x_val = []\n",
    "  y_train = []\n",
    "  y_val = []\n",
    "\n",
    "  trainSize = []\n",
    "  valSize = []\n",
    "\n",
    "  trainCount = []\n",
    "  valCount = []\n",
    "  dataSize = pd.Series(Answer).value_counts()\n",
    "  print(dataSize)\n",
    "  for i in range(len(dataSize)):\n",
    "    trainSize.append(dataSize[i] * (1 - split_size))\n",
    "    valSize.append(dataSize[i] - trainSize[i])\n",
    "    trainCount.append(0)\n",
    "    valCount.append(0)\n",
    "\n",
    "  for i in range(len(Question)):\n",
    "    dice = random.random()\n",
    "    choose = 0\n",
    "    if(dice <= split_size):\n",
    "      choose = 1\n",
    "\n",
    "    if(choose == 0):\n",
    "      if(trainCount[Answer[i]] < trainSize[Answer[i]]):\n",
    "        trainCount[Answer[i]] += 1\n",
    "        x_train.append(Question[i])\n",
    "        y_train.append(Answer[i])\n",
    "      else:\n",
    "        valCount[Answer[i]] += 1\n",
    "        x_val.append(Question[i])\n",
    "        y_val.append(Answer[i])\n",
    "    elif(choose == 1):\n",
    "      if(valCount[Answer[i]] < valCount[Answer[i]]):\n",
    "        valCount[Answer[i]] += 1\n",
    "        x_val.append(Question[i])\n",
    "        y_val.append(Answer[i])\n",
    "      else:\n",
    "        trainCount[Answer[i]] += 1\n",
    "        x_train.append(Question[i])\n",
    "        y_train.append(Answer[i])\n",
    "  print(pd.Series(y_train).value_counts())\n",
    "  print(pd.Series(y_val).value_counts())\n",
    "  return x_train, x_val, y_train, y_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model Create函数\n",
    "def create_model(max_words=max_words,mode='BiLSTM+Attention',batch_size=32,epochs=10,hidden_dim=[32],show_loss=True,show_confusion_matrix=True):\n",
    "    #构建模型\n",
    "    model=build_model(max_words=max_words,mode=mode)\n",
    "    print(model.summary())\n",
    "    es = EarlyStopping(patience=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 1000)]            0         \n",
      "                                                                 \n",
      " positional_embedding (Posi  (None, 1000, 32)          132608    \n",
      " tionalEmbedding)                                                \n",
      "                                                                 \n",
      " transformer_encoder (Trans  (None, 1000, 32)          19040     \n",
      " formerEncoder)                                                  \n",
      "                                                                 \n",
      " global_max_pooling1d (Glob  (None, 32)                0         \n",
      " alMaxPooling1D)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 151780 (592.89 KB)\n",
      "Trainable params: 151780 (592.89 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_words=len(dic)\n",
    "max_words=1000\n",
    "batch_size=16\n",
    "epochs=20\n",
    "show_confusion_matrix=True\n",
    "show_loss=True\n",
    "mode='PositionalEmbedding+Transformer'\n",
    "model = create_model(mode=mode,batch_size=batch_size,epochs=epochs,show_confusion_matrix=show_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"D:/Work/Project/School_Homework/Graduate_Project/predict_Model/reviewLabel/binFoodQualityV1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 1000)]            0         \n",
      "                                                                 \n",
      " positional_embedding_6 (Po  (None, 1000, 32)          132608    \n",
      " sitionalEmbedding)                                              \n",
      "                                                                 \n",
      " transformer_encoder_6 (Tra  (None, 1000, 32)          19040     \n",
      " nsformerEncoder)                                                \n",
      "                                                                 \n",
      " global_max_pooling1d_6 (Gl  (None, 32)                0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 151780 (592.89 KB)\n",
      "Trainable params: 151780 (592.89 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4573\n",
      "4573\n",
      "3694\n",
      "0    3694\n",
      "3     269\n",
      "4     189\n",
      "5     183\n",
      "2     142\n",
      "1      96\n",
      "Name: count, dtype: int64\n",
      "0    3090\n",
      "3     224\n",
      "4     158\n",
      "5     152\n",
      "2     119\n",
      "1      81\n",
      "Name: count, dtype: int64\n",
      "0    604\n",
      "3     45\n",
      "5     31\n",
      "4     31\n",
      "2     23\n",
      "1     15\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import emoji\n",
    "import re\n",
    "import math\n",
    "from pylab import mpl\n",
    "\n",
    "TARGET = 'food_quality'\n",
    "\n",
    "maxlen = 1000\n",
    "vocab_size = len(dic)\n",
    "# 讀取CSV文件並轉換為DataFrame\n",
    "df = pd.read_csv('maybeNegativeOrNature_foodQuality.csv')\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "texts = df['Comment'].tolist()\n",
    "\n",
    "full_size_labels = []\n",
    "full_size_encText = []\n",
    "\n",
    "labels = []\n",
    "encText = []\n",
    "\n",
    "Label0Max = float(\"INF\")\n",
    "Label0Count = 0\n",
    "\n",
    "\n",
    "PositiveMax = float(\"INF\")\n",
    "PositiveCount = 0\n",
    "for t in range(len(texts)):\n",
    "  texts[t] = emoji.demojize(texts[t])\n",
    "  texts[t] = re.sub(':\\S+?:', ' ', texts[t])\n",
    "  encs = []\n",
    "\n",
    "\n",
    "  if len(texts[t]) > maxlen:\n",
    "    texts[t] = texts[:maxlen]\n",
    "  for i in range(maxlen):\n",
    "    if(i<len(texts[t]) and texts[t][i] in dic):\n",
    "      encs.append(dic[texts[t][i]])\n",
    "    else:\n",
    "      encs.append(0)\n",
    "\n",
    "  if (encs != None) :\n",
    "    full_size_encText.append(encs)\n",
    "    if(df.iloc[t][TARGET] == 1 or df.iloc[t][TARGET] == 2):\n",
    "      full_size_labels.append(1)\n",
    "    elif(df.iloc[t][TARGET] == 4 or df.iloc[t][TARGET] == 5):\n",
    "      full_size_labels.append(3)\n",
    "    elif(df.iloc[t][TARGET] == 3):\n",
    "      full_size_labels.append(2)\n",
    "    else:\n",
    "      full_size_labels.append(df.iloc[t][TARGET]) \n",
    "\n",
    "\n",
    "  if (df.iloc[t][TARGET] == 0):\n",
    "    if(Label0Count > Label0Max):\n",
    "      continue\n",
    "    Label0Count += 1\n",
    "\n",
    "  if(df.iloc[t][TARGET] == 1 or df.iloc[t][TARGET] == 2):\n",
    "    labels.append(1)\n",
    "  elif(df.iloc[t][TARGET] == 4 or df.iloc[t][TARGET] == 5):\n",
    "    if(PositiveCount > PositiveMax):\n",
    "      continue\n",
    "\n",
    "    PositiveCount += 1\n",
    "    labels.append(3)\n",
    "  elif(df.iloc[t][TARGET] == 3):\n",
    "    labels.append(2)\n",
    "  else:\n",
    "    labels.append(df.iloc[t][TARGET]) \n",
    "  #labels.append(df.iloc[t][TARGET])\n",
    "\n",
    "  '''if (df.iloc[t][TARGET] == 1):\n",
    "    labels.append(0)\n",
    "  elif (df.iloc[t][TARGET] == -1):\n",
    "    labels.append(1)\n",
    "  else:\n",
    "    labels.append(2)'''\n",
    "\n",
    "  encText.append(encs)\n",
    "\n",
    "\n",
    "\n",
    "print(len(labels))\n",
    "print(len(texts))\n",
    "print(pd.Series(labels).value_counts()[0])\n",
    "pd.Series(labels).value_counts().plot(kind='bar')\n",
    "# 將資料集分割成訓練集和測試集\n",
    "x_train, x_val, y_train, y_val = shuffle(encText, labels, 0.2)\n",
    "# 將標籤轉換為模型所需的格式\n",
    "label_dict = {label: i for i, label in enumerate(set(labels))}\n",
    "\n",
    "\n",
    "y_train = tf.constant([label_dict[label] for label in y_train], dtype=tf.int32)  # 將資料型別轉換為 tf.int32\n",
    "y_val = tf.constant([label_dict[label] for label in y_val], dtype=tf.int32)  # 將資料型別轉換為 tf.int32\n",
    "num_classes = len(label_dict)\n",
    "\n",
    "Y_train = tf.one_hot(y_train, num_classes)\n",
    "\n",
    "Y_test_original=y_val\n",
    "Y_test = tf.one_hot(y_val, num_classes)\n",
    "\n",
    "X_train = tf.constant(x_train)\n",
    "X_test = tf.constant(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # 指定使用的GPU索引\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233/233 [==============================] - 208s 892ms/step\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    ans = model.predict(full_size_encText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lebels 0's acc analyze:\n",
      "predict:[1141, 61, 52, 189, 0, 0]\n",
      "Total: 1443\n",
      "Acc: 0.7907137907137907 \n",
      "\n",
      "lebels 1's acc analyze:\n",
      "predict:[63, 394, 66, 74, 0, 0]\n",
      "Total: 597\n",
      "Acc: 0.6599664991624791 \n",
      "\n",
      "lebels 2's acc analyze:\n",
      "predict:[59, 30, 352, 107, 0, 0]\n",
      "Total: 548\n",
      "Acc: 0.6423357664233577 \n",
      "\n",
      "lebels 3's acc analyze:\n",
      "predict:[670, 210, 468, 3515, 0, 0]\n",
      "Total: 4863\n",
      "Acc: 0.7228048529714168 \n",
      "\n",
      "Total: \n",
      "[[1141, 61, 52, 189, 0, 0], [63, 394, 66, 74, 0, 0], [59, 30, 352, 107, 0, 0], [670, 210, 468, 3515, 0, 0]]\n",
      "0.7250033552543282\n",
      "Alert\n"
     ]
    }
   ],
   "source": [
    "chk = [[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0]]\n",
    "''',[0,0,0,0,0,0],[0,0,0,0,0,0]]'''\n",
    "correct = 0\n",
    "positive = [4,5]\n",
    "negative = [1,2]\n",
    "nature = [3]\n",
    "\n",
    "checkLabel = full_size_labels\n",
    "alert = []\n",
    "for i in range(len(checkLabel)):\n",
    "  chk[checkLabel[i]][np.argmax(ans[i])] += 1\n",
    "  if checkLabel[i] == np.argmax(ans[i]):\n",
    "    correct += 1\n",
    "  if(checkLabel[i] in negative and np.argmax(ans[i]) in positive):\n",
    "    alert.append(i)\n",
    "\n",
    "for label in range(len(chk)):\n",
    "  print(f\"lebels {label}'s acc analyze:\")\n",
    "  print(f\"predict:{chk[label]}\")\n",
    "  print(f\"Total: {sum(chk[label])}\")\n",
    "  print(f\"Acc: {chk[label][label] / sum(chk[label])} \\n\")\n",
    "\n",
    "print(\"Total: \")\n",
    "print(chk)\n",
    "print(correct / len(checkLabel))\n",
    "\n",
    "print(\"Alert\")\n",
    "for i in alert:\n",
    "  print(decode(encText[i]))\n",
    "  print(f\"Ans:{checkLabel[i]}, Pred:{np.argmax(ans[i])}\")\n",
    "  print(ans[i])\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(string):\n",
    "    string = emoji.demojize(string)\n",
    "    string = re.sub(':\\S+?:', ' ', string)\n",
    "    encs = []\n",
    "    if len(string) > maxlen:\n",
    "        string = string[:maxlen]\n",
    "\n",
    "    for i in range(maxlen):\n",
    "        if(i<len(string) and string[i] in dic):\n",
    "            encs.append(dic[string[i]])\n",
    "        else:\n",
    "            encs.append(0)\n",
    "    if (encs != None) :\n",
    "        return encs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "[[0.7655105  0.03964278 0.06860557 0.12624112]]\n",
      "Pred:0\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "import re\n",
    "maxlen = 1000\n",
    "testCase = \" 看了美食部落客花露露的文章慕名而來，點了一個松露牛肉漢堡跟老墨雞腿漢堡，好吃到爆！漢堡物超所值的大顆，而且店員服務態度很好， 絕對絕對會再回訪的好店（已放入口袋名單）\"\n",
    "encText = []\n",
    "encs = []\n",
    "encText.append(encode(testCase))\n",
    "print(len(encText))\n",
    "predictions = model.predict(encText)\n",
    "print(predictions)\n",
    "print(f\"Pred:{np.argmax(predictions[0])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
